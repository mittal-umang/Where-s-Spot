{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "from tensorflow.keras import backend\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import time\n",
    "from datetime import timedelta\n",
    "\n",
    "import math\n",
    "import os\n",
    "\n",
    "import scipy.misc\n",
    "from scipy.stats import itemfreq\n",
    "from random import sample\n",
    "import pickle\n",
    "\n",
    "import PIL.Image\n",
    "from IPython.display import display\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from zipfile import ZipFile\n",
    "from io import BytesIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.0-beta1'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def absoluteFilePaths(directory):\n",
    "    list_of_files = []\n",
    "    dict_of_files={}\n",
    "    for dirpath, _, filenames in os.walk(directory):\n",
    "        for f in filenames:\n",
    "            list_of_files.append(os.path.abspath(os.path.join(dirpath, f)))\n",
    "            dict_of_files.setdefault(f.replace('.jpg', ''), os.path.abspath(os.path.join(dirpath, f)))\n",
    "\n",
    "    return list_of_files, dict_of_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_names,file_dict = absoluteFilePaths('/home/umang.mittal/dogs/train/')\n",
    "# test_file_names = absoluteFilePaths('/home/umang.mittal/dogs/test/')\n",
    "working_dir = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_raw = pd.read_csv(\"dogs/labels.csv\", header=0, sep=',', quotechar='\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conversion(raw_data):\n",
    "    return_dict = dict()\n",
    "    for index, row in raw_data.iterrows():\n",
    "        return_dict.setdefault(row[1], []).append(row[0])\n",
    "    return return_dict\n",
    "\n",
    "label_dict = conversion(labels_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# This function help to create  a pickle file gathering all the image from a zip folder\n",
    "def DataBase_creator(file_paths, nwidth, nheight, save_name):\n",
    "    s = (len(file_paths), nwidth, nheight, 3)\n",
    "    allImage = np.zeros(s)\n",
    "    for i in range(0, len(file_paths)):\n",
    "        image = PIL.Image.open(file_paths[i]) \n",
    "        image = image.resize((nwidth, nheight))\n",
    "        image = np.array(image)\n",
    "        image = np.clip(image / 255.0, 0.0, 1.0)\n",
    "        allImage[i] = image\n",
    "    pickle.dump(allImage, open(save_name + '.p', \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code for Data Augmentation using GANs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE = 1\n",
    "BATCH_SIZE = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_generator_model():\n",
    "    model = tf.keras.Sequential()\n",
    "\n",
    "    model.add(layers.Dense(7*7*768, use_bias=False, input_shape=(256,)))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Reshape((7, 7, 768)))\n",
    "    assert model.output_shape == (None, 7, 7, 768) # Note: None is the batch size\n",
    "\n",
    "    model.add(layers.Conv2DTranspose(384, (5, 5), strides=(1, 1), padding='same', use_bias=False))\n",
    "    assert model.output_shape == (None, 7, 7, 384)\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "\n",
    "    model.add(layers.Conv2DTranspose(192, (5, 5), strides=(2, 2), padding='same', use_bias=False))\n",
    "    assert model.output_shape == (None, 14, 14, 192)\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "\n",
    "    model.add(layers.Conv2DTranspose(3, (5, 5), strides=(2, 2), padding='same', use_bias=False, activation='tanh'))\n",
    "    assert model.output_shape == (None, 28, 28, 3)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f5702563410>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi40LCBodHRwOi8vbWF0cGxvdGxpYi5vcmcv7US4rQAAGSBJREFUeJzt3Xlw1dXZB/DvI/umgEAgIKKIioJFTUEKFcQFpVarUBQ77+BSsYWiTrXa8e24DGNHnbeWLpQWFUXHBaeiYpGKoBQpqAREUBZBCDsE2XcIPO8fufZNLed7YhLuje/5fmYYkvvlyT25ycO9yfmdc8zdISLpOS7XAxCR3FDziyRKzS+SKDW/SKLU/CKJUvOLJErNL5IoNb9IotT8Iomqmc07a9CggTdu3DiYx642ZLmZ0dqaNfmnevjw4Qrfd61atWhtSUkJzWNjiz0uR44coTlz3HH8///Y4xK7b/a51ahRg9YePHiQ5jGx7wkm9jWJfezY48Y+91gt+37asWMH9u7dW65PvFLNb2aXA/gdgBoAnnT3R9i/b9y4MX76058G89gnvX///mBWu3ZtWtusWTOab9++neaHDh0KZq1bt6a1mzdvpnlsbLEm2LNnTzCLNVj9+vVpHntc9u7dS/MWLVoEs4YNG9La1atX0zzWgOw/5dh/euxJCoh/v+3YsYPmxx9/fDDbtWsXrS0uLg5m48aNo7VlVfhlv5nVADAKwBUAzgIwyMzOqujHE5HsqszP/F0BLHf3Fe5+EMBLAK6ummGJyLFWmeZvDWBNmffXZm77N2Y2xMwKzayQvTwVkew65r/td/cx7l7g7gUNGjQ41ncnIuVUmeZfB+CkMu+3ydwmIt8AlWn+OQA6mNkpZlYbwPUAJlbNsETkWKvwVJ+7l5jZzwC8hdKpvrHu/imrKSkpodMUsSmtdu3aBbMlS5bQ2tiU1s6dO2nepEmTYLZq1SpaG5tuW7RoEc1jU2Lsc4v9qDV//vxK3fcll1xC8xdeeCGYsa8nALRp04bmU6ZMoflll10WzN59911a26NHD5rXqVOH5rGvOfueiV03wqYZv861DZWa53f3NwG8WZmPISK5oct7RRKl5hdJlJpfJFFqfpFEqflFEqXmF0lUVtfzmxmdo4zNjbI5Z7Z0FAA2bdpE8w4dOtCcLTeuzHp6AOjevTvNP//88wp/7MmTJ9N84MCBNI8t6f3Tn/5E8/PPPz+YxR7z2FqQ/v3703z27NnB7Morr6S1hYWFNI9dNxJblnvKKacEs3r16tHaE088MZjVrVuX1palZ36RRKn5RRKl5hdJlJpfJFFqfpFEqflFEpXVqb5atWqhZcuWwXz9+vW0ni2DPOGEE2htbMoqtiT429/+djCbOnUqrY1NSb366qs0Z0tTAWDu3LnB7Nxzz6W1EyfyLRh69epF8xi27fjo0aNp7d13303zUaNG0XzAgAHB7IMPPqC1+/bto3lsSfCtt95Kc7Yb9HvvvUdr2bLd2Pd5WXrmF0mUml8kUWp+kUSp+UUSpeYXSZSaXyRRan6RRFns+Oeq1KZNGx82bFgwP++882g9m/9cuHAhrY1dB3D66afTnG3VHNsee968eTR/+OGHK5UXFBQEs9h26N/5zndozq4hAECv2wCAL774Ipht27aN1rKTbIH415wtEY9dOxHb0ryy15WsWLEimLFl0ABfnv6HP/wBa9euLdf+3XrmF0mUml8kUWp+kUSp+UUSpeYXSZSaXyRRan6RRFVqPb+ZFQHYBeAwgBJ3D084o3T7a7al8WuvvUbvr0uXLsFs2rRptPb73/8+zRs3bkzzOXPmBLP27dvTWjZuABg+fDjNY3Px7HG77rrraO306dNpvnv3bpovW7aM5mxd+89//nNa27p1a5p/9tlnNGePa15eHq2NHXX98ccf0zx2vDjbOpx9rwHxI7zLqyo287jI3cNXcohItaSX/SKJqmzzO4ApZjbXzIZUxYBEJDsq+7K/p7uvM7MWAN42syXuPqPsP8j8pzAEiF+rLSLZU6lnfndfl/m7GMCrALoe5d+McfcCdy+InW8mItlT4eY3swZm1ujLtwFcBuCTqhqYiBxblXnZnwfg1cyUSE0AL7j736tkVCJyzGV1PX9+fr4PGRL+vWBsXfxHH30UzDZu3Ehre/ToQfM333yT5uwo69jabnbeABCfc37//fdpztbzz5o1i9becMMNNN+8eTPN3377bZp37tw5mPXs2ZPWxj7vxYsX05wdAd6qVStaGzvqumZN/ry5cuVKmk+ZMiWYDRo0iNayvSVGjBiBoqIirecXkTA1v0ii1PwiiVLziyRKzS+SKDW/SKKyekS3u9OtpP/5z3/S+m7dugWz2FbJp512Gs1j03FsGnLSpEm0tmPHjjSPbY998skn05xt9XzkyBFaO3LkSJrHlhvHtgbfuXNnMIsdRR1bTtyvXz+as23Dn3jiCVr74x//mOZjx46l+RVXXEHzH/7wh8Fs5syZtHbv3r3BTEd0i0iUml8kUWp+kUSp+UUSpeYXSZSaXyRRan6RRGV1SW/btm39nnvuCeYHDhyg9Xv27Almsa23//53vtXAM888Q/MXXnghmMWWd06dOpXmL730Es2HDh1K8zPOOCOYnX322bQ2trXaunXraF5SUkLzCRMmBLP+/ftX6r7ZPD7ArxOIHQe/b98+mseWkPft25fma9asCWb/+Mc/aO1JJ50UzP7yl79g3bp1WtIrImFqfpFEqflFEqXmF0mUml8kUWp+kUSp+UUSldX1/AcOHMCKFSuCeWwtcvPmzYNZbOvt22+/neb3338/zdm8b2zL8WuvvZbmbC4ciG/lzNZ/x46KXrt2Lc2Li4tpHtsH4fLLLw9mo0ePprWXXnopzWNz7X/84x+DWWy9fpMmTWg+e/Zsmu/fv5/mxx0Xft5lW3MD/NqKr3Pdjp75RRKl5hdJlJpfJFFqfpFEqflFEqXmF0mUml8kUdF5fjMbC+BKAMXu3ilzW1MA4wG0A1AEYKC7b4t9rNi+/bH96Rs2bBjMOnXqRGtr1apFczO+BPqUU04JZhdffDGtfeedd2heVFRE89ic8c033xzMbrvtNlobm+/Oz8+neWyenx11fdVVV9HaQ4cO0bxPnz40f/nll4NZr169aO2mTZtoftNNN9GcHScP8L0pYnsNsGs3YtcIlFWeZ/5nAHz1So1fApjm7h0ATMu8LyLfINHmd/cZALZ+5earAYzLvD0OwA+qeFwicoxV9Gf+PHffkHl7I4C8KhqPiGRJpX/h56UXEwcvKDazIWZWaGaFsX3RRCR7Ktr8m8ysFQBk/g6u/nD3Me5e4O4F9erVq+DdiUhVq2jzTwQwOPP2YACvV81wRCRbos1vZi8CmA3gDDNba2a3AHgEwKVmtgzAJZn3ReQbJKv79rdv395//etfB/PYev6FCxcGs9g1AmyfdACoXbs2zdn1CRs2bAhmALBkyRKax+bSL7roIpq/9tprwaxz5860Nvb1b9euHc0XLFhA84EDBwYzdkY9wOfpgfgeDBdeeGEwe+ONN2jtU089RfPYOQ89e/as8MeP7T2xbVv4kpqRI0dizZo12rdfRMLU/CKJUvOLJErNL5IoNb9IotT8IonK6lRffn6+syWmbGtugB9dfOaZZ9La2JTUt771LZqzo67ZFCQALF++nOZ5eXxpRGw5MlvqHFta+uSTT9L80Ucfpfkjj/BLPNhU3/e+9z1au3LlSpq3aNGC5myaMral+XXXXUfzBx54gOax74mOHTsGs9iR7e3btw9m48ePR3Fxsab6RCRMzS+SKDW/SKLU/CKJUvOLJErNL5IoNb9IorI6z9+iRQtn876xZbf9+vULZuzobyC+7DY2H86uT2DbUwPxLahjy0eHDx9Oc7b1d9++fWntjTfeSPPYkuDYtuJsaWts2+/TTjuN5uyYa6D0SPiQLVu20NqmTZvSPHbdyA033EDz+vXrB7MpU6bQWnas+uTJk7FlyxbN84tImJpfJFFqfpFEqflFEqXmF0mUml8kUWp+kURFj+iu0jurWRPNmjUL5mz+EgCWLl0azLp27UprzzrrLJrH1tR/+OGHwezaa6+ltbE177GjqmPbivfu3TuYffzxx7T27rvvpvnGjRtpzq7bAPg1DEeOHKG1sROeYnP148ePD2ax6xvY9xoAnH766TTfvXs3zadOnRrMzjnnHFrL9iKYMWMGrS1Lz/wiiVLziyRKzS+SKDW/SKLU/CKJUvOLJErNL5Ko6Dy/mY0FcCWAYnfvlLntQQC3Atic+Wf3ufub0TuLzPPH5rNZ3r17d1o7atQomm/atInm3/3ud4PZs88+S2sHDBhA8+eff57msTMFLrnkkmBWo0YNWhub548dFx1be872QXjsscdobWyvgNh5COeff34w++STT2jtjh07KnXfixcvpjn7fjr++OMrfN+xvSPKKs8z/zMALj/K7b919y6ZP9HGF5HqJdr87j4DwNYsjEVEsqgyP/P/zMwWmNlYM2tSZSMSkayoaPOPBtAeQBcAGwD8JvQPzWyImRWaWWHsemcRyZ4KNb+7b3L3w+5+BMATAIKratx9jLsXuHsBO1BSRLKrQs1vZq3KvHsNAP6rUxGpdsoz1fcigN4AmpnZWgAPAOhtZl0AOIAiAOH5HBGplrK6b3/r1q192LBh4cEY3258586dwSy2br1Lly40j+2zvnnz5mD24osv0trGjRvTPLY//cSJE2l+8803B7NFixbR2tjjsmTJEprH5uIbNWoUzGL7INx7770079WrF81nzpwZzGJfk9j+EJMmTaL5FVdcQXN2LsCsWbNoLdtL4KGHHkJRUZH27ReRMDW/SKLU/CKJUvOLJErNL5IoNb9IorK6dfehQ4fo9tzbt2+n9X369AlmY8aMobVt27al+TXXXEPzQYMGBbPLLruM1s6ZM4fmbDoMAC6//GiLKv/P7Nmzgxk7vhsA5s+fT/NLL72U5q+88grN77///mA2evRoWhtbCn3TTTfRnE3HxaZPn3zySZr/6Ec/onlsipUdLx7b0pwdN1/VS3pF5P8hNb9IotT8IolS84skSs0vkig1v0ii1Pwiicrqkt42bdr48OHDg3nsyGU2H75v3z5au3r1aprH5tLnzp1b4fuOLdmNLWXeu3cvzdnSVjZuAFi2bBnNS0pKaH799dfT/M9//nMw69SpE6294IILaB67xoBtWx5bsvvXv/6V5ueeey7Na9WqRXN2fQW7pgTgy4GHDh2KpUuXakmviISp+UUSpeYXSZSaXyRRan6RRKn5RRKl5hdJVFbX8x8+fBi7du0K5u3ataP1q1atCmaxI7bXr19P83vuuYfmQ4cODWYbN26ktcXFxTSPrfe/8cYbaX7gwIFgVrduXVrLjrEGgG3bttF8+vTpNG/VqlUwi9W2bNmS5itXrqQ5W3P/+9//ntayrzcAvPHGGzQvKCigOTuqnu3PAJQedR8SO1q8LD3ziyRKzS+SKDW/SKLU/CKJUvOLJErNL5IoNb9IoqLz/GZ2EoBnAeQBcABj3P13ZtYUwHgA7QAUARjo7nRS+MiRI3Rt+tatW+lY2Prsbt260dqGDRvSPDaX/umnnwaz2DUEzZs3p3n//v1pnpeXV+GPz85JiNUCwJ49e2ge2w+CfU3feecdWvuLX/yC5g8//DDNR40aFcwuvvhiWsv2xgeAn/zkJzSPnZfAjpuP7Q9x3nnnBbP69evT2rLK88xfAuAudz8LwAUAhpnZWQB+CWCau3cAMC3zvoh8Q0Sb3903uPu8zNu7ACwG0BrA1QDGZf7ZOAA/OFaDFJGq97V+5jezdgDOBfABgDx3//K10UaU/lggIt8Q5W5+M2sI4BUAd7r7v/3A4qU/+B31hz8zG2JmhWZWGPtZRkSyp1zNb2a1UNr4z7v7hMzNm8ysVSZvBeCoq1fcfYy7F7h7Qb169apizCJSBaLNb6Vbyz4FYLG7P14mmghgcObtwQBer/rhicixUp4lvT0A/BeAhWb25X7D9wF4BMDLZnYLgFUABsY+UJ06dXDqqacG8+eff57W33LLLcHs5ZdfprV9+/al+eDBg2n+q1/9Kpi1bt2a1rZo0YLmn332Gc3PPvtsmrNtoGNTeU899RTNH330UZr36NGD5nfccUcwq+yW5gsWLKD5kCFDgtnIkSNpbWzqN7aEvHbt2jRn07exqd3NmzcHs69zRHe0+d19JoDQV4FPlopItaUr/EQSpeYXSZSaXyRRan6RRKn5RRKl5hdJVFaP6M7Pz/fbbrstmLMluwDott9r1qyhtR06dKB5bC594cKFwSw2j9+lSxeax47gfuutt2jep0+fYMbmhAGgbdu2NH/9dX7tFtuaG+DbsS9dupTWnnPOOTTfvXs3zdmS4dgR2mw7dCA+jx9bWnvyyScHM7bcF+Bz+U8//TQ2bNigI7pFJEzNL5IoNb9IotT8IolS84skSs0vkig1v0iisnpEd82aNdG4ceNg/v7779P6AQMGBLPVq1fTWrb1NgD87W9/o/ldd90VzNjR4QAwefJkms+YMYPmPXv2pDl7TEeMGEFru3btSnM2Hw3EH/cLLrggmN1+++20NnZs+qxZs2jOtrhevnw5rT3hhBNozq77KE89u0ahUaNGtPbw4cMVyr5Kz/wiiVLziyRKzS+SKDW/SKLU/CKJUvOLJErNL5KorK7nb9asmV911VXBPLb/PVubfuaZZ9La2N74sX372d74LVu2pLVsHwIAKCkpoXnNmvxyjOLiox6WBCC+rjy2nj82Hx47ipqte+/evTutLSwspHm/fv1ofueddwazBx54gNbG1tRv3LiR5kuWLKE5m49ft24drWVHuo8YMQJFRUVazy8iYWp+kUSp+UUSpeYXSZSaXyRRan6RRKn5RRIVXc9vZicBeBZAHgAHMMbdf2dmDwK4FcCXk+/3ufub7GPVrVuX7p+/YsUKOha2X/mkSZNo7fDhw2n+0ksv0ZydC7BlyxZa27t3b5p/8MEHNI9dR/Dcc88FswkTJtDaxx9/nOaxc+pj69qvvPLKCtdu2LCB5rH1/t26dQtmsesTnn76aZo/8cQTNI+dZ8Du/9RTT6W106dPD2axa0rKKs9mHiUA7nL3eWbWCMBcM3s7k/3W3f+n3PcmItVGtPndfQOADZm3d5nZYgD8UjwRqfa+1s/8ZtYOwLkAvnyd+jMzW2BmY82sSaBmiJkVmlnhnj17KjVYEak65W5+M2sI4BUAd7r7TgCjAbQH0AWlrwx+c7Q6dx/j7gXuXtCgQYMqGLKIVIVyNb+Z1UJp4z/v7hMAwN03ufthdz8C4AkAfCdIEalWos1vZgbgKQCL3f3xMreX/XXmNQA+qfrhicixEl3Sa2Y9AbwHYCGAI5mb7wMwCKUv+R1AEYDbMr8cDMrPz/dbb701mOfl5dGxsCOdY0tX9+/fT/NOnTrR/KOPPgpmseO969WrR/PYMdqx5aUdO3YMZvPmzaO1zZs3p3nscWPTaQA/fjy2ZDd2ZHt+fj7NmQ8//JDmbdq0oXnsiO6tW7fS/MQTTwxmsaljdnT5Qw89VO4lveX5bf9MAEf7YHROX0SqN13hJ5IoNb9IotT8IolS84skSs0vkig1v0iisnpEt7vj4MGDwXz9+vW0nm0zHTsqOvax69SpQ3N2HUBsLnzZsmU0LygooPmiRYto3rRp02C2fft2WhvbYnrgwIE0Z0udAb5leuwak86dO9M8Nh/OPvfYVu+xeXz2mAPxpbV169YNZrGxbdu2LZjpiG4RiVLziyRKzS+SKDW/SKLU/CKJUvOLJErNL5KorB7RbWabAawqc1MzAF9kbQBfT3UdW3UdF6CxVVRVju1kd+ebNGRktfn/487NCt2dX+GSI9V1bNV1XIDGVlG5Gpte9oskSs0vkqhcN/+YHN8/U13HVl3HBWhsFZWTseX0Z34RyZ1cP/OLSI7kpPnN7HIzW2pmy83sl7kYQ4iZFZnZQjObb2Z8b+ljP5axZlZsZp+Uua2pmb1tZssyfx/1mLQcje1BM1uXeezmm1m/HI3tJDN718wWmdmnZnZH5vacPnZkXDl53LL+st/MagD4DMClANYCmANgkLvzRetZYmZFAArcPedzwmZ2IYDdAJ51906Z2x4DsNXdH8n8x9nE3e+tJmN7EMDuXJ/cnDlQplXZk6UB/ADAjcjhY0fGNRA5eNxy8czfFcByd1/h7gcBvATg6hyMo9pz9xkAvnr6w9UAxmXeHofSb56sC4ytWnD3De4+L/P2LgBfniyd08eOjCsnctH8rQGU3f5lLarXkd8OYIqZzTWzIbkezFHklTkZaSMAfsxR9kVPbs6mr5wsXW0eu4qceF3V9Au//9TT3c8DcAWAYZmXt9WSl/7MVp2ma8p1cnO2HOVk6X/J5WNX0ROvq1oumn8dgJPKvN8mc1u14O7rMn8XA3gV1e/04U1fHpKa+bs4x+P5l+p0cvPRTpZGNXjsqtOJ17lo/jkAOpjZKWZWG8D1ACbmYBz/wcwaZH4RAzNrAOAyVL/ThycCGJx5ezCA13M4ln9TXU5uDp0sjRw/dtXuxGt3z/ofAP1Q+hv/zwH8dy7GEBjXqQA+zvz5NNdjA/AiSl8GHkLp70ZuAXAigGkAlgGYCqBpNRrbcyg9zXkBShutVY7G1hOlL+kXAJif+dMv148dGVdOHjdd4SeSKP3CTyRRan6RRKn5RRKl5hdJlJpfJFFqfpFEqflFEqXmF0nU/wKbFrv8ewBNwQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "generator = make_generator_model()\n",
    "\n",
    "noise = tf.random.normal([1,256])\n",
    "\n",
    "generated_image = generator(noise, training=False)\n",
    "\n",
    "plt.imshow(generated_image[0, :, :, 0], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_discriminator_model():\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.Conv2D(64, (5, 5), strides=(2, 2), padding='same',\n",
    "                                     input_shape=[28, 28, 3]))\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Dropout(0.3))\n",
    "\n",
    "    model.add(layers.Conv2D(128, (5, 5), strides=(2, 2), padding='same'))\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Dropout(0.3))\n",
    "\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(1))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[-0.00458491]], shape=(1, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "discriminator = make_discriminator_model()\n",
    "decision = discriminator(generated_image)\n",
    "print (decision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator_loss(real_output, fake_output):\n",
    "    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
    "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
    "    total_loss = real_loss + fake_loss\n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_loss(fake_output):\n",
    "    return cross_entropy(tf.ones_like(fake_output), fake_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_optimizer = tf.keras.optimizers.Adam(1e-3)\n",
    "discriminator_optimizer = tf.keras.optimizers.Adam(1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = './training_checkpoints'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "checkpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,\n",
    "                                 discriminator_optimizer=discriminator_optimizer,\n",
    "                                 generator=generator,\n",
    "                                 discriminator=discriminator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 50\n",
    "noise_dim = 256\n",
    "num_examples_to_generate = 50\n",
    "\n",
    "seed = tf.random.normal([num_examples_to_generate, noise_dim])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@tf.function\n",
    "def train_step(images):\n",
    "    \n",
    "    noise = tf.random.normal([BATCH_SIZE, noise_dim])\n",
    "\n",
    "\n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "        generated_images = generator(noise, training=True)\n",
    "        real_output = discriminator(images, training=True)\n",
    "        fake_output = discriminator(generated_images, training=True)\n",
    "\n",
    "        gen_loss = generator_loss(fake_output)\n",
    "        disc_loss = discriminator_loss(real_output, fake_output)\n",
    "\n",
    "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
    "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
    "\n",
    "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
    "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_file_dict = {}\n",
    "def train_gans(dataset, epochs,breed):\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        start = time.time()\n",
    "\n",
    "        for image_batch in dataset:\n",
    "            train_step(image_batch)\n",
    "\n",
    "    predictions = generator(seed, training=False)\n",
    "    fig = plt.figure(figsize=(4,4))\n",
    "    \n",
    "    breed_dict = {}\n",
    "    \n",
    "    for i in range(predictions.shape[0]):\n",
    "        plt.imshow(predictions[i, :, :, 0] * 127.5 + 127.5, cmap='gray')\n",
    "        plt.axis('off')\n",
    "        \n",
    "        file_name = 'image_generated_{:04d}'.format(i)\n",
    "        path = working_dir+'/dogs/train/'+breed+'/'+file_name+'.jpg'\n",
    "        plt.savefig(path)\n",
    "        breed_dict.setdefault(file_name,path)\n",
    "        generated_file_dict.setdefault(breed,breed_dict)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_file_path(key):\n",
    "    file_paths=[]\n",
    "    for label in label_dict.get(key):\n",
    "        file_paths.append(file_dict.get(label))\n",
    "    return file_paths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0712 13:23:40.910890 140013339109184 deprecation.py:323] From /home/umang.mittal/.local/lib/python2.7/site-packages/tensorflow/python/ops/nn_impl.py:182: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "image_resize = 28\n",
    "\n",
    "for key in label_dict.keys():\n",
    "    DataBase_creator(file_paths = get_file_path(key), nwidth = image_resize, nheight = image_resize , save_name = \"train_\"+key)\n",
    "    train = pickle.load(open('train_'+key+'.p',\"rb\")).astype('float32')\n",
    "    train = (train - 127.5) / 127.5\n",
    "    train_dataset = tf.data.Dataset.from_tensor_slices(train).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\n",
    "    train_gans(train_dataset,EPOCHS,key)\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Block to update label_raw with new files and breed\n",
    "\n",
    "for breed in generated_file_dict.keys():\n",
    "    for value in generated_file_dict.get(breed).keys():\n",
    "        labels_raw = labels_raw.append({\"breed\":breed,\"id\":value},ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0713 05:15:10.630295 140537321613120 deprecation.py:323] From /home/umang.mittal/.local/lib/python2.7/site-packages/tensorflow/python/compat/v2_compat.py:65: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = tf.ConfigProto(intra_op_parallelism_threads=8, inter_op_parallelism_threads=8, \\\n",
    "                        allow_soft_placement=True, device_count = {'CPU': 8})\n",
    "session = tf.Session(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.0-beta1'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels_raw.to_csv('./new_labels.csv',index=False)\n",
    "labels_raw = pd.read_csv(\"./new_labels.csv\", header=0, sep=',', quotechar='\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_resize = 28\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_names,file_dict = absoluteFilePaths('/home/umang.mittal/dogs/train/')\n",
    "test_file_names,test_dict = absoluteFilePaths('/home/umang.mittal/dogs/test/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16222"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(file_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "DataBase_creator(file_paths = file_names, nwidth = image_resize, nheight = image_resize , save_name = \"train\")\n",
    "DataBase_creator(file_paths = test_file_names, nwidth = image_resize, nheight = image_resize , save_name = \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pickle.load( open( \"train.p\", \"rb\" ) )\n",
    "test = pickle.load( open( \"test.p\", \"rb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16222, 1)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = labels_raw[\"breed\"].as_matrix()\n",
    "labels = labels.reshape(labels.shape[0],1) #labels.shape[0] looks faster than using len(labels)\n",
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matrix_Bin(labels):\n",
    "    labels_bin=np.array([])\n",
    "\n",
    "    labels_name, labels0 = np.unique(labels, return_inverse=True)\n",
    "    labels0\n",
    "    \n",
    "    for _, i in enumerate(itemfreq(labels0)[:,0].astype(int)):\n",
    "        labels_bin0 = np.where(labels0 == itemfreq(labels0)[:,0][i], 1., 0.)\n",
    "        labels_bin0 = labels_bin0.reshape(1,labels_bin0.shape[0])\n",
    "\n",
    "        if (labels_bin.shape[0] == 0):\n",
    "            labels_bin = labels_bin0\n",
    "        else:\n",
    "            labels_bin = np.concatenate((labels_bin,labels_bin0 ),axis=0)\n",
    "\n",
    "    print(\"Nber SubVariables {0}\".format(itemfreq(labels0)[:,0].shape[0]))\n",
    "    labels_bin = labels_bin.transpose()\n",
    "    print(\"Shape : {0}\".format(labels_bin.shape))\n",
    "    \n",
    "    return labels_name, labels_bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nber SubVariables 120\n",
      "Shape : (16222, 120)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_name, labels_bin = matrix_Bin(labels = labels)\n",
    "labels_bin[0:9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_validation = 0.30\n",
    "train_test_split = X_train, X_validation, y_train, y_validation = train_test_split(train, labels_bin, test_size=num_validation, random_state=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  3,  41,  38,  56, 112,  34, 115,  50,  79])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def train_test_creation(x, data, toPred): \n",
    "    indices = sample(range(data.shape[0]),int(x * data.shape[0])) \n",
    "    indices = np.sort(indices, axis=None) \n",
    "\n",
    "    index = np.arange(data.shape[0]) \n",
    "    reverse_index = np.delete(index, indices,0)\n",
    "\n",
    "    train_toUse = data[indices]\n",
    "    train_toPred = toPred[indices]\n",
    "    test_toUse = data[reverse_index]\n",
    "    test_toPred = toPred[reverse_index]\n",
    "\n",
    "    return train_toUse, train_toPred, test_toUse, test_toPred\n",
    "\n",
    "df_train_toUse, df_train_toPred, df_test_toUse, df_test_toPred = train_test_creation(0.7, train, labels_bin)\n",
    "\n",
    "df_validation_toPred_cls = np.argmax(y_validation, axis=1)\n",
    "df_validation_toPred_cls[0:9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = image_resize\n",
    "num_channels = 3\n",
    "img_size_flat = img_size * img_size\n",
    "img_shape = (img_size, img_size, num_channels)\n",
    "num_classes = 120\n",
    "\n",
    "def new_weights(shape):\n",
    "    return tf.Variable(tf.truncated_normal(shape, stddev=0.05))\n",
    "\n",
    "\n",
    "def new_biases(length):\n",
    "    return tf.Variable(tf.constant(0.05, shape=[length]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_conv_layer(input,              \n",
    "                   num_input_channels, \n",
    "                   filter_size,        \n",
    "                   num_filters,        \n",
    "                   use_pooling=True,\n",
    "                   use_dropout=True):  \n",
    "\n",
    "\n",
    "    shape = [filter_size, filter_size, num_input_channels, num_filters]\n",
    "\n",
    "\n",
    "    weights = new_weights(shape=shape)\n",
    "\n",
    "\n",
    "    biases = new_biases(length=num_filters)\n",
    "\n",
    "    layer = tf.nn.conv2d(input=input,\n",
    "                         filter=weights,\n",
    "                         strides=[1, 1, 1, 1],\n",
    "                         padding='SAME')\n",
    "    layer += biases\n",
    "    if use_pooling:\n",
    "        layer = tf.nn.max_pool(value=layer,\n",
    "                               ksize=[1, 2, 2, 1],\n",
    "                               strides=[1, 2, 2, 1],\n",
    "                               padding='SAME')\n",
    "\n",
    "    layer = tf.nn.relu(layer)\n",
    "    \n",
    "    if use_dropout:\n",
    "        layer = tf.nn.dropout(layer,keep_prob_conv)\n",
    "    return layer, weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_layer(layer):\n",
    "\n",
    "    layer_shape = layer.get_shape()\n",
    "\n",
    "    num_features = layer_shape[1:4].num_elements()\n",
    "    layer_flat = tf.reshape(layer, [-1, num_features])\n",
    "\n",
    "    return layer_flat, num_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_fc_layer(input,          \n",
    "                 num_inputs,     \n",
    "                 num_outputs,    \n",
    "                 use_relu=True,\n",
    "                 use_dropout=True):\n",
    "\n",
    "    weights = new_weights(shape=[num_inputs, num_outputs])\n",
    "    biases = new_biases(length=num_outputs)\n",
    "    layer = tf.matmul(input, weights) + biases\n",
    "\n",
    "\n",
    "    if use_relu:\n",
    "        layer = tf.nn.relu(layer)\n",
    "    \n",
    "    if use_dropout:\n",
    "        layer = tf.nn.dropout(layer,keep_prob_fc)\n",
    "        \n",
    "    return layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, shape=[None, img_size, img_size, num_channels], name='x')\n",
    "x_image = tf.reshape(x, [-1, img_size, img_size, num_channels]) \n",
    "y_true = tf.placeholder(tf.float32, shape=[None, num_classes], name='y_true')\n",
    "y_true_cls = tf.argmax(y_true, axis=1)\n",
    "keep_prob_fc=tf.placeholder(tf.float32)\n",
    "keep_prob_conv=tf.placeholder(tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0713 05:17:24.704636 140537321613120 deprecation.py:506] From <ipython-input-22-3f910d0a0dbb>:31: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "filter_size1 = 5          \n",
    "num_filters1 = 32         \n",
    "\n",
    "\n",
    "\n",
    "filter_size2 = 4          \n",
    "num_filters2 = 64      \n",
    "\n",
    "\n",
    "\n",
    "filter_size3 = 3       \n",
    "num_filters3 = 128     \n",
    "\n",
    "\n",
    "fc_size = 500 \n",
    "\n",
    "layer_conv1, weights_conv1 = \\\n",
    "    new_conv_layer(input=x_image,\n",
    "                   num_input_channels=num_channels,\n",
    "                   filter_size=filter_size1,\n",
    "                   num_filters=num_filters1,\n",
    "                   use_pooling=True,\n",
    "                   use_dropout=False)\n",
    "    \n",
    "layer_conv2, weights_conv2 = \\\n",
    "    new_conv_layer(input=layer_conv1,\n",
    "                   num_input_channels=num_filters1,\n",
    "                   filter_size=filter_size2,\n",
    "                   num_filters=num_filters2,\n",
    "                   use_pooling=True,\n",
    "                   use_dropout=False)\n",
    "    \n",
    "layer_conv3, weights_conv3 = \\\n",
    "    new_conv_layer(input=layer_conv2,\n",
    "                   num_input_channels=num_filters2,\n",
    "                   filter_size=filter_size3,\n",
    "                   num_filters=num_filters3,\n",
    "                   use_pooling=True,\n",
    "                   use_dropout=True)\n",
    "\n",
    "layer_flat, num_features = flatten_layer(layer_conv3)\n",
    "\n",
    "\n",
    "layer_fc1 = new_fc_layer(input=layer_flat,\n",
    "                         num_inputs=num_features,\n",
    "                         num_outputs=fc_size,\n",
    "                         use_relu=True,\n",
    "                         use_dropout=True)\n",
    "\n",
    "layer_fc2 = new_fc_layer(input=layer_fc1,\n",
    "                         num_inputs=fc_size,\n",
    "                         num_outputs=num_classes,\n",
    "                         use_relu=False,\n",
    "                         use_dropout=False)\n",
    "\n",
    "\n",
    "y_pred = tf.nn.softmax(layer_fc2)\n",
    "y_pred_cls = tf.argmax(y_pred, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'ArgMax_1:0' shape=(?,) dtype=int64>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_cls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0713 05:17:24.763304 140537321613120 deprecation.py:323] From <ipython-input-27-23540ee58a4e>:1: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cross_entropy = tf.nn.softmax_cross_entropy_with_logits(logits=layer_fc2, labels=y_true)\n",
    "cost = tf.reduce_mean(cross_entropy)\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=1e-3).minimize(cost)\n",
    "correct_prediction = tf.equal(y_pred_cls, y_true_cls)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def init_variables():\n",
    "    session.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 50\n",
    "\n",
    "\n",
    "def next_batch(num, data, labels):\n",
    "    '''\n",
    "    Return a total of `num` random samples and labels. \n",
    "    '''\n",
    "    idx = np.arange(0 , len(data))\n",
    "    np.random.shuffle(idx)\n",
    "    idx = idx[:num]\n",
    "    data_shuffle = [data[i] for i in idx]\n",
    "    labels_shuffle = [labels[i] for i in idx]\n",
    "\n",
    "\n",
    "    return np.asarray(data_shuffle), np.asarray(labels_shuffle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize(num_iterations, output_divisor):\n",
    "    global total_iterations\n",
    "\n",
    "    start_time = time.time()\n",
    "    losses = {'train': [], 'validation': []}\n",
    "\n",
    "    for i in range(num_iterations):\n",
    "        total_iterations += 1\n",
    "        x_batch, y_true_batch = next_batch(batch_size, X_train, y_train)\n",
    "\n",
    "        feed_dict_train = {x: x_batch,\n",
    "                           y_true: y_true_batch,\n",
    "                           keep_prob_conv: 0.3,\n",
    "                           keep_prob_fc: 0.4}\n",
    "        feed_dict_validation = {x: X_validation,\n",
    "                                y_true: y_validation,\n",
    "                                keep_prob_conv: 1,\n",
    "                                keep_prob_fc: 1}\n",
    "\n",
    "        session.run(optimizer, feed_dict=feed_dict_train)\n",
    "\n",
    "        acc_train = session.run(accuracy, feed_dict=feed_dict_train)\n",
    "        acc_validation = session.run(accuracy, feed_dict=feed_dict_validation)\n",
    "        losses['train'].append(acc_train)\n",
    "        losses['validation'].append(acc_validation)\n",
    "\n",
    "        if (total_iterations % output_divisor == 0) or (i == (num_iterations - 1)):\n",
    "            msg = \"Iteration: {0:>6}, Training Accuracy: {1:>6.1%}, Validation Accuracy: {2:>6.1%}\"\n",
    "            print(msg.format(total_iterations, acc_train, acc_validation))\n",
    "\n",
    "    end_time = time.time()\n",
    "\n",
    "    time_dif = end_time - start_time\n",
    "    print(\"Time usage: \" + str(timedelta(seconds=int(round(time_dif)))))\n",
    "\n",
    "    plt.plot(losses['train'], label='Training loss')\n",
    "    plt.plot(losses['validation'], label='Validation loss')\n",
    "    plt.legend()\n",
    "    _ = plt.ylim()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:    250, Training Accuracy:   0.0%, Validation Accuracy:   0.8%\n",
      "Iteration:    500, Training Accuracy:   6.0%, Validation Accuracy:   0.7%\n",
      "Iteration:    750, Training Accuracy:   0.0%, Validation Accuracy:   1.1%\n",
      "Iteration:   1000, Training Accuracy:   0.0%, Validation Accuracy:   0.8%\n",
      "Iteration:   1250, Training Accuracy:   0.0%, Validation Accuracy:   1.0%\n",
      "Iteration:   1500, Training Accuracy:   2.0%, Validation Accuracy:   1.0%\n",
      "Iteration:   1750, Training Accuracy:   2.0%, Validation Accuracy:   1.2%\n",
      "Iteration:   2000, Training Accuracy:   0.0%, Validation Accuracy:   1.0%\n",
      "Iteration:   2250, Training Accuracy:   2.0%, Validation Accuracy:   0.8%\n",
      "Iteration:   2500, Training Accuracy:   0.0%, Validation Accuracy:   0.8%\n",
      "Iteration:   2750, Training Accuracy:   0.0%, Validation Accuracy:   0.8%\n",
      "Iteration:   3000, Training Accuracy:   2.0%, Validation Accuracy:   0.8%\n",
      "Iteration:   3250, Training Accuracy:   2.0%, Validation Accuracy:   1.2%\n",
      "Iteration:   3500, Training Accuracy:   0.0%, Validation Accuracy:   1.0%\n",
      "Iteration:   3750, Training Accuracy:   0.0%, Validation Accuracy:   0.7%\n",
      "Iteration:   4000, Training Accuracy:   0.0%, Validation Accuracy:   0.7%\n",
      "Iteration:   4250, Training Accuracy:   2.0%, Validation Accuracy:   0.9%\n",
      "Iteration:   4500, Training Accuracy:   0.0%, Validation Accuracy:   0.9%\n",
      "Iteration:   4750, Training Accuracy:   0.0%, Validation Accuracy:   0.8%\n",
      "Iteration:   5000, Training Accuracy:   2.0%, Validation Accuracy:   0.9%\n",
      "Iteration:   5250, Training Accuracy:   0.0%, Validation Accuracy:   0.9%\n",
      "Iteration:   5500, Training Accuracy:   2.0%, Validation Accuracy:   0.9%\n",
      "Iteration:   5750, Training Accuracy:   2.0%, Validation Accuracy:   0.9%\n",
      "Iteration:   6000, Training Accuracy:   0.0%, Validation Accuracy:   0.8%\n",
      "Iteration:   6250, Training Accuracy:   0.0%, Validation Accuracy:   0.9%\n",
      "Iteration:   6500, Training Accuracy:   0.0%, Validation Accuracy:   0.9%\n",
      "Iteration:   6750, Training Accuracy:   0.0%, Validation Accuracy:   0.9%\n",
      "Iteration:   7250, Training Accuracy:   2.0%, Validation Accuracy:   0.8%\n",
      "Iteration:   7500, Training Accuracy:   4.0%, Validation Accuracy:   0.8%\n",
      "Iteration:   7750, Training Accuracy:   0.0%, Validation Accuracy:   0.8%\n",
      "Iteration:   8000, Training Accuracy:   0.0%, Validation Accuracy:   0.8%\n",
      "Iteration:   8250, Training Accuracy:   2.0%, Validation Accuracy:   0.8%\n",
      "Iteration:   8500, Training Accuracy:   0.0%, Validation Accuracy:   0.8%\n",
      "Iteration:   8750, Training Accuracy:   0.0%, Validation Accuracy:   1.1%\n",
      "Iteration:   9000, Training Accuracy:   0.0%, Validation Accuracy:   0.8%\n"
     ]
    }
   ],
   "source": [
    "init_variables()\n",
    "total_iterations = 0\n",
    "optimize(num_iterations=10000, output_divisor=250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_vars=tf.global_variables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Add ops to save and restore all the variables.\n",
    "saver = tf.train.Saver(all_vars)\n",
    "\n",
    "save_path = saver.save(session, \"/home/umang.mittal/Where-s-Spot/myproject/wherespot/recon_model3.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "feed_dict_validation = {x: X_validation, y_true: y_validation, keep_prob_conv : 1, keep_prob_fc : 1}\n",
    "df_validation_Predicted_cls = session.run(y_pred_cls, feed_dict=feed_dict_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<type 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(type(X_validation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
